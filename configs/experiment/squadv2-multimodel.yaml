# @package _global_

# to execute this experiment run:
# python train.py experiment=squadv2-multimodel

defaults:
  - sqadv2-multimodel_base.yaml

model:
  pretrained_models:
    bert-base-cased: "bert-base-cased"
    bert-base-cased-ner-ontonotes: "models/pretrained/bert-base-cased-ner-ontonotes"
    # bert-base-cased-re-tacred: "models/pretrained/bert-base-cased-re-tacred"
  pretrained_configs:
    bert-base-cased-re-tacred:
      vocab_size: 29000
